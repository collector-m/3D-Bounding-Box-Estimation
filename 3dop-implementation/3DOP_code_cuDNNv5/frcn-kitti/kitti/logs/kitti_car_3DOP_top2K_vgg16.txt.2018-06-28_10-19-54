+ echo Logging output to kitti/logs/kitti_car_3DOP_top2K_vgg16.txt.2018-06-28_10-19-54
Logging output to kitti/logs/kitti_car_3DOP_top2K_vgg16.txt.2018-06-28_10-19-54
+ ./tools/train_net.py --gpu 1 --solver kitti/models/kitti_car/VGG16/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb kitti_car_train --cfg kitti/cfgs/kitti_car_3DOP_top2K.yml
Called with args:
Namespace(cfg_file='kitti/cfgs/kitti_car_3DOP_top2K.yml', gpu_id=1, imdb_name='kitti_car_train', max_iters=40000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, solver='kitti/models/kitti_car/VGG16/solver.prototxt')
Using config:
{'BOX_NUM': 2000,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'kitti_car_3DOP_top2K',
 'PIXEL_MEANS': array([[[ 95.8814,  98.7743,  93.8549]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/media/rajatmittal/1a4b8e66-3d01-4a83-8e7b-52054acd44f2/3dop-implementation/3DOP_code_cuDNNv5/frcn-kitti',
 'TEST': {'BBOX_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.4,
          'ORT_REG': True,
          'PROPOSAL_METHOD': '3DOP',
          'SCALES': [1295],
          'SVM': False},
 'TRAIN': {'BATCH_SIZE': 128,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.7,
           'BG_THRESH_HI': 0.7,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.7,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'ORT_REG': True,
           'ORT_THRESH': 0.7,
           'PROPOSAL_METHOD': '3DOP',
           'SCALES': [1295],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False}}
/media/rajatmittal/1a4b8e66-3d01-4a83-8e7b-52054acd44f2/3dop-implementation/3DOP_code_cuDNNv5/frcn-kitti/tools/../lib/datasets/../../data/kitti/object/training
Loaded dataset `kitti_car_train` for training
Appending horizontally-flipped training examples...
kitti_car_train 3DOP roidb loaded from /media/rajatmittal/1a4b8e66-3d01-4a83-8e7b-52054acd44f2/3dop-implementation/3DOP_code_cuDNNv5/frcn-kitti/data/cache/kitti_car_train_3DOP_top2000_roidb.pkl
done
Preparing training data...
done
Output will be saved to `/media/rajatmittal/1a4b8e66-3d01-4a83-8e7b-52054acd44f2/3dop-implementation/3DOP_code_cuDNNv5/frcn-kitti/output/kitti_car_3DOP_top2K/kitti_car_train`
Filtered 1582 roidb entries: 7424 -> 5842
Computing bounding-box regression targets...
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0628 10:19:57.720690 23389 solver.cpp:48] Initializing solver from parameters: 
train_net: "kitti/models/kitti_car/VGG16/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 30000
snapshot: 0
snapshot_prefix: "vgg16_frcn_kitti"
average_loss: 100
I0628 10:19:57.720731 23389 solver.cpp:81] Creating training net from train_net file: kitti/models/kitti_car/VGG16/train.prototxt
I0628 10:19:57.721213 23389 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_loss_weights"
  top: "ort_targets"
  top: "ort_loss_weights"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "multi_rois"
  type: "Python"
  bottom: "rois"
  top: "context"
  python_param {
    module: "roi_data_layer.layer"
    layer: "MultiRoIDataLayer"
    param_str: "\'context\': 1.5"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "roi_pool5_context"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "context"
  top: "pool5_context"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6_context"
  type: "InnerProduct"
  bottom: "pool5_context"
  top: "fc6_context"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6_context"
  type: "ReLU"
  bottom: "fc6_context"
  top: "fc6_context"
}
layer {
  name: "drop6_context"
  type: "Dropout"
  bottom: "fc6_context"
  top: "fc6_context"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_context"
  type: "InnerProduct"
  bottom: "fc6_context"
  top: "fc7_context"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7_context"
  type: "ReLU"
  bottom: "fc7_context"
  top: "fc7_context"
}
layer {
  name: "drop7_context"
  type: "Dropout"
  bottom: "fc7_context"
  top: "fc7_context"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_output"
  type: "Concat"
  bottom: "fc7"
  bottom: "fc7_context"
  top: "fc7_output"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7_output"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7_output"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ort_pred"
  type: "InnerProduct"
  bottom: "fc7_output"
  top: "ort_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_loss_weights"
  top: "loss_bbox"
  loss_weight: 1
}
layer {
  name: "loss_ort"
  type: "SmoothL1Loss"
  bottom: "ort_pred"
  bottom: "ort_targets"
  bottom: "ort_loss_weights"
  top: "loss_ort"
  loss_weight: 1
}
I0628 10:19:57.721385 23389 layer_factory.hpp:77] Creating layer data
I0628 10:19:57.721792 23389 net.cpp:100] Creating Layer data
I0628 10:19:57.721801 23389 net.cpp:408] data -> data
I0628 10:19:57.721807 23389 net.cpp:408] data -> rois
I0628 10:19:57.721812 23389 net.cpp:408] data -> labels
I0628 10:19:57.721817 23389 net.cpp:408] data -> bbox_targets
I0628 10:19:57.721822 23389 net.cpp:408] data -> bbox_loss_weights
I0628 10:19:57.721827 23389 net.cpp:408] data -> ort_targets
I0628 10:19:57.721830 23389 net.cpp:408] data -> ort_loss_weights
I0628 10:19:57.738950 23389 net.cpp:150] Setting up data
I0628 10:19:57.738970 23389 net.cpp:157] Top shape: 1 3 100 100 (30000)
I0628 10:19:57.738973 23389 net.cpp:157] Top shape: 1 5 (5)
I0628 10:19:57.738976 23389 net.cpp:157] Top shape: 1 (1)
I0628 10:19:57.738978 23389 net.cpp:157] Top shape: 1 8 (8)
I0628 10:19:57.738981 23389 net.cpp:157] Top shape: 1 8 (8)
I0628 10:19:57.738983 23389 net.cpp:157] Top shape: 1 2 (2)
I0628 10:19:57.738986 23389 net.cpp:157] Top shape: 1 2 (2)
I0628 10:19:57.738986 23389 net.cpp:165] Memory required for data: 120104
I0628 10:19:57.738991 23389 layer_factory.hpp:77] Creating layer rois_data_1_split
I0628 10:19:57.739002 23389 net.cpp:100] Creating Layer rois_data_1_split
I0628 10:19:57.739006 23389 net.cpp:434] rois_data_1_split <- rois
I0628 10:19:57.739012 23389 net.cpp:408] rois_data_1_split -> rois_data_1_split_0
I0628 10:19:57.739022 23389 net.cpp:408] rois_data_1_split -> rois_data_1_split_1
I0628 10:19:57.739063 23389 net.cpp:150] Setting up rois_data_1_split
I0628 10:19:57.739069 23389 net.cpp:157] Top shape: 1 5 (5)
I0628 10:19:57.739073 23389 net.cpp:157] Top shape: 1 5 (5)
I0628 10:19:57.739075 23389 net.cpp:165] Memory required for data: 120144
I0628 10:19:57.739078 23389 layer_factory.hpp:77] Creating layer multi_rois
I0628 10:19:57.739112 23389 net.cpp:100] Creating Layer multi_rois
I0628 10:19:57.739117 23389 net.cpp:434] multi_rois <- rois_data_1_split_0
I0628 10:19:57.739122 23389 net.cpp:408] multi_rois -> context
'context': 1.5
I0628 10:19:57.739471 23389 net.cpp:150] Setting up multi_rois
I0628 10:19:57.739478 23389 net.cpp:157] Top shape: 1 5 (5)
I0628 10:19:57.739480 23389 net.cpp:165] Memory required for data: 120164
I0628 10:19:57.739483 23389 layer_factory.hpp:77] Creating layer conv1_1
I0628 10:19:57.739491 23389 net.cpp:100] Creating Layer conv1_1
I0628 10:19:57.739493 23389 net.cpp:434] conv1_1 <- data
I0628 10:19:57.739497 23389 net.cpp:408] conv1_1 -> conv1_1
I0628 10:19:57.741716 23389 net.cpp:150] Setting up conv1_1
I0628 10:19:57.741729 23389 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0628 10:19:57.741732 23389 net.cpp:165] Memory required for data: 2680164
I0628 10:19:57.741741 23389 layer_factory.hpp:77] Creating layer relu1_1
I0628 10:19:57.741750 23389 net.cpp:100] Creating Layer relu1_1
I0628 10:19:57.741751 23389 net.cpp:434] relu1_1 <- conv1_1
I0628 10:19:57.741755 23389 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0628 10:19:57.741761 23389 net.cpp:150] Setting up relu1_1
I0628 10:19:57.741765 23389 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0628 10:19:57.741766 23389 net.cpp:165] Memory required for data: 5240164
I0628 10:19:57.741768 23389 layer_factory.hpp:77] Creating layer conv1_2
I0628 10:19:57.741775 23389 net.cpp:100] Creating Layer conv1_2
I0628 10:19:57.741777 23389 net.cpp:434] conv1_2 <- conv1_1
I0628 10:19:57.741783 23389 net.cpp:408] conv1_2 -> conv1_2
I0628 10:19:57.743072 23389 net.cpp:150] Setting up conv1_2
I0628 10:19:57.743083 23389 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0628 10:19:57.743100 23389 net.cpp:165] Memory required for data: 7800164
I0628 10:19:57.743106 23389 layer_factory.hpp:77] Creating layer relu1_2
I0628 10:19:57.743111 23389 net.cpp:100] Creating Layer relu1_2
I0628 10:19:57.743114 23389 net.cpp:434] relu1_2 <- conv1_2
I0628 10:19:57.743119 23389 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0628 10:19:57.743122 23389 net.cpp:150] Setting up relu1_2
I0628 10:19:57.743126 23389 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0628 10:19:57.743129 23389 net.cpp:165] Memory required for data: 10360164
I0628 10:19:57.743134 23389 layer_factory.hpp:77] Creating layer pool1
I0628 10:19:57.743139 23389 net.cpp:100] Creating Layer pool1
I0628 10:19:57.743140 23389 net.cpp:434] pool1 <- conv1_2
I0628 10:19:57.743144 23389 net.cpp:408] pool1 -> pool1
I0628 10:19:57.743191 23389 net.cpp:150] Setting up pool1
I0628 10:19:57.743194 23389 net.cpp:157] Top shape: 1 64 50 50 (160000)
I0628 10:19:57.743196 23389 net.cpp:165] Memory required for data: 11000164
I0628 10:19:57.743198 23389 layer_factory.hpp:77] Creating layer conv2_1
I0628 10:19:57.743204 23389 net.cpp:100] Creating Layer conv2_1
I0628 10:19:57.743207 23389 net.cpp:434] conv2_1 <- pool1
I0628 10:19:57.743212 23389 net.cpp:408] conv2_1 -> conv2_1
I0628 10:19:57.744433 23389 net.cpp:150] Setting up conv2_1
I0628 10:19:57.744443 23389 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0628 10:19:57.744462 23389 net.cpp:165] Memory required for data: 12280164
I0628 10:19:57.744467 23389 layer_factory.hpp:77] Creating layer relu2_1
I0628 10:19:57.744472 23389 net.cpp:100] Creating Layer relu2_1
I0628 10:19:57.744475 23389 net.cpp:434] relu2_1 <- conv2_1
I0628 10:19:57.744479 23389 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0628 10:19:57.744484 23389 net.cpp:150] Setting up relu2_1
I0628 10:19:57.744487 23389 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0628 10:19:57.744489 23389 net.cpp:165] Memory required for data: 13560164
I0628 10:19:57.744491 23389 layer_factory.hpp:77] Creating layer conv2_2
I0628 10:19:57.744495 23389 net.cpp:100] Creating Layer conv2_2
I0628 10:19:57.744498 23389 net.cpp:434] conv2_2 <- conv2_1
I0628 10:19:57.744503 23389 net.cpp:408] conv2_2 -> conv2_2
I0628 10:19:57.744854 23389 net.cpp:150] Setting up conv2_2
I0628 10:19:57.744860 23389 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0628 10:19:57.744863 23389 net.cpp:165] Memory required for data: 14840164
I0628 10:19:57.744866 23389 layer_factory.hpp:77] Creating layer relu2_2
I0628 10:19:57.744870 23389 net.cpp:100] Creating Layer relu2_2
I0628 10:19:57.744873 23389 net.cpp:434] relu2_2 <- conv2_2
I0628 10:19:57.744875 23389 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0628 10:19:57.744879 23389 net.cpp:150] Setting up relu2_2
I0628 10:19:57.744882 23389 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0628 10:19:57.744884 23389 net.cpp:165] Memory required for data: 16120164
I0628 10:19:57.744886 23389 layer_factory.hpp:77] Creating layer pool2
I0628 10:19:57.744890 23389 net.cpp:100] Creating Layer pool2
I0628 10:19:57.744892 23389 net.cpp:434] pool2 <- conv2_2
I0628 10:19:57.744896 23389 net.cpp:408] pool2 -> pool2
I0628 10:19:57.744940 23389 net.cpp:150] Setting up pool2
I0628 10:19:57.744946 23389 net.cpp:157] Top shape: 1 128 25 25 (80000)
I0628 10:19:57.744948 23389 net.cpp:165] Memory required for data: 16440164
I0628 10:19:57.744951 23389 layer_factory.hpp:77] Creating layer conv3_1
I0628 10:19:57.744956 23389 net.cpp:100] Creating Layer conv3_1
I0628 10:19:57.744958 23389 net.cpp:434] conv3_1 <- pool2
I0628 10:19:57.744963 23389 net.cpp:408] conv3_1 -> conv3_1
I0628 10:19:57.746325 23389 net.cpp:150] Setting up conv3_1
I0628 10:19:57.746335 23389 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0628 10:19:57.746337 23389 net.cpp:165] Memory required for data: 17080164
I0628 10:19:57.746345 23389 layer_factory.hpp:77] Creating layer relu3_1
I0628 10:19:57.746348 23389 net.cpp:100] Creating Layer relu3_1
I0628 10:19:57.746351 23389 net.cpp:434] relu3_1 <- conv3_1
I0628 10:19:57.746356 23389 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0628 10:19:57.746361 23389 net.cpp:150] Setting up relu3_1
I0628 10:19:57.746364 23389 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0628 10:19:57.746366 23389 net.cpp:165] Memory required for data: 17720164
I0628 10:19:57.746368 23389 layer_factory.hpp:77] Creating layer conv3_2
I0628 10:19:57.746373 23389 net.cpp:100] Creating Layer conv3_2
I0628 10:19:57.746376 23389 net.cpp:434] conv3_2 <- conv3_1
I0628 10:19:57.746381 23389 net.cpp:408] conv3_2 -> conv3_2
I0628 10:19:57.747978 23389 net.cpp:150] Setting up conv3_2
I0628 10:19:57.747989 23389 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0628 10:19:57.747992 23389 net.cpp:165] Memory required for data: 18360164
I0628 10:19:57.747997 23389 layer_factory.hpp:77] Creating layer relu3_2
I0628 10:19:57.748003 23389 net.cpp:100] Creating Layer relu3_2
I0628 10:19:57.748006 23389 net.cpp:434] relu3_2 <- conv3_2
I0628 10:19:57.748010 23389 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0628 10:19:57.748014 23389 net.cpp:150] Setting up relu3_2
I0628 10:19:57.748018 23389 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0628 10:19:57.748019 23389 net.cpp:165] Memory required for data: 19000164
I0628 10:19:57.748021 23389 layer_factory.hpp:77] Creating layer conv3_3
I0628 10:19:57.748028 23389 net.cpp:100] Creating Layer conv3_3
I0628 10:19:57.748029 23389 net.cpp:434] conv3_3 <- conv3_2
I0628 10:19:57.748034 23389 net.cpp:408] conv3_3 -> conv3_3
I0628 10:19:57.749642 23389 net.cpp:150] Setting up conv3_3
I0628 10:19:57.749653 23389 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0628 10:19:57.749656 23389 net.cpp:165] Memory required for data: 19640164
I0628 10:19:57.749661 23389 layer_factory.hpp:77] Creating layer relu3_3
I0628 10:19:57.749665 23389 net.cpp:100] Creating Layer relu3_3
I0628 10:19:57.749670 23389 net.cpp:434] relu3_3 <- conv3_3
I0628 10:19:57.749675 23389 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0628 10:19:57.749680 23389 net.cpp:150] Setting up relu3_3
I0628 10:19:57.749683 23389 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0628 10:19:57.749686 23389 net.cpp:165] Memory required for data: 20280164
I0628 10:19:57.749687 23389 layer_factory.hpp:77] Creating layer pool3
I0628 10:19:57.749692 23389 net.cpp:100] Creating Layer pool3
I0628 10:19:57.749696 23389 net.cpp:434] pool3 <- conv3_3
I0628 10:19:57.749701 23389 net.cpp:408] pool3 -> pool3
I0628 10:19:57.749749 23389 net.cpp:150] Setting up pool3
I0628 10:19:57.749753 23389 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0628 10:19:57.749755 23389 net.cpp:165] Memory required for data: 20453220
I0628 10:19:57.749758 23389 layer_factory.hpp:77] Creating layer conv4_1
I0628 10:19:57.749763 23389 net.cpp:100] Creating Layer conv4_1
I0628 10:19:57.749766 23389 net.cpp:434] conv4_1 <- pool3
I0628 10:19:57.749771 23389 net.cpp:408] conv4_1 -> conv4_1
I0628 10:19:57.752249 23389 net.cpp:150] Setting up conv4_1
I0628 10:19:57.752262 23389 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0628 10:19:57.752265 23389 net.cpp:165] Memory required for data: 20799332
I0628 10:19:57.752270 23389 layer_factory.hpp:77] Creating layer relu4_1
I0628 10:19:57.752274 23389 net.cpp:100] Creating Layer relu4_1
I0628 10:19:57.752279 23389 net.cpp:434] relu4_1 <- conv4_1
I0628 10:19:57.752282 23389 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0628 10:19:57.752286 23389 net.cpp:150] Setting up relu4_1
I0628 10:19:57.752290 23389 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0628 10:19:57.752292 23389 net.cpp:165] Memory required for data: 21145444
I0628 10:19:57.752295 23389 layer_factory.hpp:77] Creating layer conv4_2
I0628 10:19:57.752300 23389 net.cpp:100] Creating Layer conv4_2
I0628 10:19:57.752302 23389 net.cpp:434] conv4_2 <- conv4_1
I0628 10:19:57.752308 23389 net.cpp:408] conv4_2 -> conv4_2
I0628 10:19:57.756875 23389 net.cpp:150] Setting up conv4_2
I0628 10:19:57.756896 23389 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0628 10:19:57.756899 23389 net.cpp:165] Memory required for data: 21491556
I0628 10:19:57.756911 23389 layer_factory.hpp:77] Creating layer relu4_2
I0628 10:19:57.756919 23389 net.cpp:100] Creating Layer relu4_2
I0628 10:19:57.756924 23389 net.cpp:434] relu4_2 <- conv4_2
I0628 10:19:57.756930 23389 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0628 10:19:57.756937 23389 net.cpp:150] Setting up relu4_2
I0628 10:19:57.756940 23389 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0628 10:19:57.756942 23389 net.cpp:165] Memory required for data: 21837668
I0628 10:19:57.756944 23389 layer_factory.hpp:77] Creating layer conv4_3
I0628 10:19:57.756952 23389 net.cpp:100] Creating Layer conv4_3
I0628 10:19:57.756954 23389 net.cpp:434] conv4_3 <- conv4_2
I0628 10:19:57.756960 23389 net.cpp:408] conv4_3 -> conv4_3
I0628 10:19:57.761283 23389 net.cpp:150] Setting up conv4_3
I0628 10:19:57.761307 23389 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0628 10:19:57.761308 23389 net.cpp:165] Memory required for data: 22183780
I0628 10:19:57.761315 23389 layer_factory.hpp:77] Creating layer relu4_3
I0628 10:19:57.761322 23389 net.cpp:100] Creating Layer relu4_3
I0628 10:19:57.761327 23389 net.cpp:434] relu4_3 <- conv4_3
I0628 10:19:57.761332 23389 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0628 10:19:57.761339 23389 net.cpp:150] Setting up relu4_3
I0628 10:19:57.761343 23389 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0628 10:19:57.761344 23389 net.cpp:165] Memory required for data: 22529892
I0628 10:19:57.761346 23389 layer_factory.hpp:77] Creating layer pool4
I0628 10:19:57.761351 23389 net.cpp:100] Creating Layer pool4
I0628 10:19:57.761353 23389 net.cpp:434] pool4 <- conv4_3
I0628 10:19:57.761359 23389 net.cpp:408] pool4 -> pool4
I0628 10:19:57.761421 23389 net.cpp:150] Setting up pool4
I0628 10:19:57.761428 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.761430 23389 net.cpp:165] Memory required for data: 22630244
I0628 10:19:57.761433 23389 layer_factory.hpp:77] Creating layer conv5_1
I0628 10:19:57.761440 23389 net.cpp:100] Creating Layer conv5_1
I0628 10:19:57.761443 23389 net.cpp:434] conv5_1 <- pool4
I0628 10:19:57.761448 23389 net.cpp:408] conv5_1 -> conv5_1
I0628 10:19:57.765530 23389 net.cpp:150] Setting up conv5_1
I0628 10:19:57.765544 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.765547 23389 net.cpp:165] Memory required for data: 22730596
I0628 10:19:57.765552 23389 layer_factory.hpp:77] Creating layer relu5_1
I0628 10:19:57.765558 23389 net.cpp:100] Creating Layer relu5_1
I0628 10:19:57.765560 23389 net.cpp:434] relu5_1 <- conv5_1
I0628 10:19:57.765564 23389 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0628 10:19:57.765569 23389 net.cpp:150] Setting up relu5_1
I0628 10:19:57.765573 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.765573 23389 net.cpp:165] Memory required for data: 22830948
I0628 10:19:57.765576 23389 layer_factory.hpp:77] Creating layer conv5_2
I0628 10:19:57.765581 23389 net.cpp:100] Creating Layer conv5_2
I0628 10:19:57.765583 23389 net.cpp:434] conv5_2 <- conv5_1
I0628 10:19:57.765588 23389 net.cpp:408] conv5_2 -> conv5_2
I0628 10:19:57.769511 23389 net.cpp:150] Setting up conv5_2
I0628 10:19:57.769526 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.769528 23389 net.cpp:165] Memory required for data: 22931300
I0628 10:19:57.769532 23389 layer_factory.hpp:77] Creating layer relu5_2
I0628 10:19:57.769539 23389 net.cpp:100] Creating Layer relu5_2
I0628 10:19:57.769541 23389 net.cpp:434] relu5_2 <- conv5_2
I0628 10:19:57.769546 23389 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0628 10:19:57.769551 23389 net.cpp:150] Setting up relu5_2
I0628 10:19:57.769553 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.769556 23389 net.cpp:165] Memory required for data: 23031652
I0628 10:19:57.769558 23389 layer_factory.hpp:77] Creating layer conv5_3
I0628 10:19:57.769564 23389 net.cpp:100] Creating Layer conv5_3
I0628 10:19:57.769565 23389 net.cpp:434] conv5_3 <- conv5_2
I0628 10:19:57.769569 23389 net.cpp:408] conv5_3 -> conv5_3
I0628 10:19:57.773707 23389 net.cpp:150] Setting up conv5_3
I0628 10:19:57.773744 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.773747 23389 net.cpp:165] Memory required for data: 23132004
I0628 10:19:57.773753 23389 layer_factory.hpp:77] Creating layer relu5_3
I0628 10:19:57.773766 23389 net.cpp:100] Creating Layer relu5_3
I0628 10:19:57.773768 23389 net.cpp:434] relu5_3 <- conv5_3
I0628 10:19:57.773774 23389 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0628 10:19:57.773780 23389 net.cpp:150] Setting up relu5_3
I0628 10:19:57.773784 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.773787 23389 net.cpp:165] Memory required for data: 23232356
I0628 10:19:57.773788 23389 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0628 10:19:57.773792 23389 net.cpp:100] Creating Layer conv5_3_relu5_3_0_split
I0628 10:19:57.773794 23389 net.cpp:434] conv5_3_relu5_3_0_split <- conv5_3
I0628 10:19:57.773798 23389 net.cpp:408] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0628 10:19:57.773803 23389 net.cpp:408] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0628 10:19:57.773855 23389 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0628 10:19:57.773860 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.773862 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.773867 23389 net.cpp:165] Memory required for data: 23433060
I0628 10:19:57.773870 23389 layer_factory.hpp:77] Creating layer roi_pool5
I0628 10:19:57.773876 23389 net.cpp:100] Creating Layer roi_pool5
I0628 10:19:57.773880 23389 net.cpp:434] roi_pool5 <- conv5_3_relu5_3_0_split_0
I0628 10:19:57.773885 23389 net.cpp:434] roi_pool5 <- rois_data_1_split_1
I0628 10:19:57.773890 23389 net.cpp:408] roi_pool5 -> pool5
I0628 10:19:57.773895 23389 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0628 10:19:57.773938 23389 net.cpp:150] Setting up roi_pool5
I0628 10:19:57.773943 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:57.773946 23389 net.cpp:165] Memory required for data: 23533412
I0628 10:19:57.773948 23389 layer_factory.hpp:77] Creating layer fc6
I0628 10:19:57.773953 23389 net.cpp:100] Creating Layer fc6
I0628 10:19:57.773955 23389 net.cpp:434] fc6 <- pool5
I0628 10:19:57.773959 23389 net.cpp:408] fc6 -> fc6
I0628 10:19:58.121577 23389 net.cpp:150] Setting up fc6
I0628 10:19:58.121606 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.121608 23389 net.cpp:165] Memory required for data: 23549796
I0628 10:19:58.121616 23389 layer_factory.hpp:77] Creating layer relu6
I0628 10:19:58.121624 23389 net.cpp:100] Creating Layer relu6
I0628 10:19:58.121628 23389 net.cpp:434] relu6 <- fc6
I0628 10:19:58.121632 23389 net.cpp:395] relu6 -> fc6 (in-place)
I0628 10:19:58.121640 23389 net.cpp:150] Setting up relu6
I0628 10:19:58.121644 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.121644 23389 net.cpp:165] Memory required for data: 23566180
I0628 10:19:58.121646 23389 layer_factory.hpp:77] Creating layer drop6
I0628 10:19:58.121651 23389 net.cpp:100] Creating Layer drop6
I0628 10:19:58.121654 23389 net.cpp:434] drop6 <- fc6
I0628 10:19:58.121657 23389 net.cpp:395] drop6 -> fc6 (in-place)
I0628 10:19:58.121700 23389 net.cpp:150] Setting up drop6
I0628 10:19:58.121702 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.121704 23389 net.cpp:165] Memory required for data: 23582564
I0628 10:19:58.121706 23389 layer_factory.hpp:77] Creating layer fc7
I0628 10:19:58.121712 23389 net.cpp:100] Creating Layer fc7
I0628 10:19:58.121716 23389 net.cpp:434] fc7 <- fc6
I0628 10:19:58.121719 23389 net.cpp:408] fc7 -> fc7
I0628 10:19:58.148855 23389 net.cpp:150] Setting up fc7
I0628 10:19:58.148891 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.148895 23389 net.cpp:165] Memory required for data: 23598948
I0628 10:19:58.148903 23389 layer_factory.hpp:77] Creating layer relu7
I0628 10:19:58.148910 23389 net.cpp:100] Creating Layer relu7
I0628 10:19:58.148914 23389 net.cpp:434] relu7 <- fc7
I0628 10:19:58.148921 23389 net.cpp:395] relu7 -> fc7 (in-place)
I0628 10:19:58.148927 23389 net.cpp:150] Setting up relu7
I0628 10:19:58.148929 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.148931 23389 net.cpp:165] Memory required for data: 23615332
I0628 10:19:58.148933 23389 layer_factory.hpp:77] Creating layer drop7
I0628 10:19:58.148938 23389 net.cpp:100] Creating Layer drop7
I0628 10:19:58.148941 23389 net.cpp:434] drop7 <- fc7
I0628 10:19:58.148943 23389 net.cpp:395] drop7 -> fc7 (in-place)
I0628 10:19:58.148967 23389 net.cpp:150] Setting up drop7
I0628 10:19:58.148970 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.148972 23389 net.cpp:165] Memory required for data: 23631716
I0628 10:19:58.148974 23389 layer_factory.hpp:77] Creating layer roi_pool5_context
I0628 10:19:58.148979 23389 net.cpp:100] Creating Layer roi_pool5_context
I0628 10:19:58.148983 23389 net.cpp:434] roi_pool5_context <- conv5_3_relu5_3_0_split_1
I0628 10:19:58.148985 23389 net.cpp:434] roi_pool5_context <- context
I0628 10:19:58.148989 23389 net.cpp:408] roi_pool5_context -> pool5_context
I0628 10:19:58.149000 23389 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0628 10:19:58.149055 23389 net.cpp:150] Setting up roi_pool5_context
I0628 10:19:58.149060 23389 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 10:19:58.149062 23389 net.cpp:165] Memory required for data: 23732068
I0628 10:19:58.149065 23389 layer_factory.hpp:77] Creating layer fc6_context
I0628 10:19:58.149070 23389 net.cpp:100] Creating Layer fc6_context
I0628 10:19:58.149071 23389 net.cpp:434] fc6_context <- pool5_context
I0628 10:19:58.149075 23389 net.cpp:408] fc6_context -> fc6_context
I0628 10:19:58.473870 23389 net.cpp:150] Setting up fc6_context
I0628 10:19:58.473912 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.473914 23389 net.cpp:165] Memory required for data: 23748452
I0628 10:19:58.473923 23389 layer_factory.hpp:77] Creating layer relu6_context
I0628 10:19:58.473930 23389 net.cpp:100] Creating Layer relu6_context
I0628 10:19:58.473935 23389 net.cpp:434] relu6_context <- fc6_context
I0628 10:19:58.473942 23389 net.cpp:395] relu6_context -> fc6_context (in-place)
I0628 10:19:58.473948 23389 net.cpp:150] Setting up relu6_context
I0628 10:19:58.473951 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.473953 23389 net.cpp:165] Memory required for data: 23764836
I0628 10:19:58.473955 23389 layer_factory.hpp:77] Creating layer drop6_context
I0628 10:19:58.473959 23389 net.cpp:100] Creating Layer drop6_context
I0628 10:19:58.473961 23389 net.cpp:434] drop6_context <- fc6_context
I0628 10:19:58.473965 23389 net.cpp:395] drop6_context -> fc6_context (in-place)
I0628 10:19:58.473989 23389 net.cpp:150] Setting up drop6_context
I0628 10:19:58.473992 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.473994 23389 net.cpp:165] Memory required for data: 23781220
I0628 10:19:58.473995 23389 layer_factory.hpp:77] Creating layer fc7_context
I0628 10:19:58.474000 23389 net.cpp:100] Creating Layer fc7_context
I0628 10:19:58.474002 23389 net.cpp:434] fc7_context <- fc6_context
I0628 10:19:58.474006 23389 net.cpp:408] fc7_context -> fc7_context
I0628 10:19:58.500751 23389 net.cpp:150] Setting up fc7_context
I0628 10:19:58.500788 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.500790 23389 net.cpp:165] Memory required for data: 23797604
I0628 10:19:58.500804 23389 layer_factory.hpp:77] Creating layer relu7_context
I0628 10:19:58.500813 23389 net.cpp:100] Creating Layer relu7_context
I0628 10:19:58.500818 23389 net.cpp:434] relu7_context <- fc7_context
I0628 10:19:58.500823 23389 net.cpp:395] relu7_context -> fc7_context (in-place)
I0628 10:19:58.500829 23389 net.cpp:150] Setting up relu7_context
I0628 10:19:58.500831 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.500833 23389 net.cpp:165] Memory required for data: 23813988
I0628 10:19:58.500835 23389 layer_factory.hpp:77] Creating layer drop7_context
I0628 10:19:58.500839 23389 net.cpp:100] Creating Layer drop7_context
I0628 10:19:58.500843 23389 net.cpp:434] drop7_context <- fc7_context
I0628 10:19:58.500845 23389 net.cpp:395] drop7_context -> fc7_context (in-place)
I0628 10:19:58.500870 23389 net.cpp:150] Setting up drop7_context
I0628 10:19:58.500874 23389 net.cpp:157] Top shape: 1 4096 (4096)
I0628 10:19:58.500875 23389 net.cpp:165] Memory required for data: 23830372
I0628 10:19:58.500877 23389 layer_factory.hpp:77] Creating layer fc7_output
I0628 10:19:58.500881 23389 net.cpp:100] Creating Layer fc7_output
I0628 10:19:58.500883 23389 net.cpp:434] fc7_output <- fc7
I0628 10:19:58.500888 23389 net.cpp:434] fc7_output <- fc7_context
I0628 10:19:58.500891 23389 net.cpp:408] fc7_output -> fc7_output
I0628 10:19:58.500916 23389 net.cpp:150] Setting up fc7_output
I0628 10:19:58.500921 23389 net.cpp:157] Top shape: 1 8192 (8192)
I0628 10:19:58.500923 23389 net.cpp:165] Memory required for data: 23863140
I0628 10:19:58.500926 23389 layer_factory.hpp:77] Creating layer fc7_output_fc7_output_0_split
I0628 10:19:58.500931 23389 net.cpp:100] Creating Layer fc7_output_fc7_output_0_split
I0628 10:19:58.500932 23389 net.cpp:434] fc7_output_fc7_output_0_split <- fc7_output
I0628 10:19:58.500936 23389 net.cpp:408] fc7_output_fc7_output_0_split -> fc7_output_fc7_output_0_split_0
I0628 10:19:58.500941 23389 net.cpp:408] fc7_output_fc7_output_0_split -> fc7_output_fc7_output_0_split_1
I0628 10:19:58.500946 23389 net.cpp:408] fc7_output_fc7_output_0_split -> fc7_output_fc7_output_0_split_2
I0628 10:19:58.500993 23389 net.cpp:150] Setting up fc7_output_fc7_output_0_split
I0628 10:19:58.500995 23389 net.cpp:157] Top shape: 1 8192 (8192)
I0628 10:19:58.500998 23389 net.cpp:157] Top shape: 1 8192 (8192)
I0628 10:19:58.500999 23389 net.cpp:157] Top shape: 1 8192 (8192)
I0628 10:19:58.501001 23389 net.cpp:165] Memory required for data: 23961444
I0628 10:19:58.501004 23389 layer_factory.hpp:77] Creating layer cls_score
I0628 10:19:58.501010 23389 net.cpp:100] Creating Layer cls_score
I0628 10:19:58.501013 23389 net.cpp:434] cls_score <- fc7_output_fc7_output_0_split_0
I0628 10:19:58.501016 23389 net.cpp:408] cls_score -> cls_score
I0628 10:19:58.501265 23389 net.cpp:150] Setting up cls_score
I0628 10:19:58.501269 23389 net.cpp:157] Top shape: 1 2 (2)
I0628 10:19:58.501271 23389 net.cpp:165] Memory required for data: 23961452
I0628 10:19:58.501276 23389 layer_factory.hpp:77] Creating layer bbox_pred
I0628 10:19:58.501281 23389 net.cpp:100] Creating Layer bbox_pred
I0628 10:19:58.501282 23389 net.cpp:434] bbox_pred <- fc7_output_fc7_output_0_split_1
I0628 10:19:58.501286 23389 net.cpp:408] bbox_pred -> bbox_pred
I0628 10:19:58.501914 23389 net.cpp:150] Setting up bbox_pred
I0628 10:19:58.501919 23389 net.cpp:157] Top shape: 1 8 (8)
I0628 10:19:58.501921 23389 net.cpp:165] Memory required for data: 23961484
I0628 10:19:58.501925 23389 layer_factory.hpp:77] Creating layer ort_pred
I0628 10:19:58.501929 23389 net.cpp:100] Creating Layer ort_pred
I0628 10:19:58.501931 23389 net.cpp:434] ort_pred <- fc7_output_fc7_output_0_split_2
I0628 10:19:58.501936 23389 net.cpp:408] ort_pred -> ort_pred
I0628 10:19:58.502182 23389 net.cpp:150] Setting up ort_pred
I0628 10:19:58.502187 23389 net.cpp:157] Top shape: 1 2 (2)
I0628 10:19:58.502189 23389 net.cpp:165] Memory required for data: 23961492
I0628 10:19:58.502192 23389 layer_factory.hpp:77] Creating layer loss_cls
I0628 10:19:58.502197 23389 net.cpp:100] Creating Layer loss_cls
I0628 10:19:58.502199 23389 net.cpp:434] loss_cls <- cls_score
I0628 10:19:58.502202 23389 net.cpp:434] loss_cls <- labels
I0628 10:19:58.502207 23389 net.cpp:408] loss_cls -> loss_cls
I0628 10:19:58.502212 23389 layer_factory.hpp:77] Creating layer loss_cls
I0628 10:19:58.502305 23389 net.cpp:150] Setting up loss_cls
I0628 10:19:58.502310 23389 net.cpp:157] Top shape: (1)
I0628 10:19:58.502311 23389 net.cpp:160]     with loss weight 1
I0628 10:19:58.502321 23389 net.cpp:165] Memory required for data: 23961496
I0628 10:19:58.502323 23389 layer_factory.hpp:77] Creating layer loss_bbox
I0628 10:19:58.502327 23389 net.cpp:100] Creating Layer loss_bbox
I0628 10:19:58.502329 23389 net.cpp:434] loss_bbox <- bbox_pred
I0628 10:19:58.502333 23389 net.cpp:434] loss_bbox <- bbox_targets
I0628 10:19:58.502336 23389 net.cpp:434] loss_bbox <- bbox_loss_weights
I0628 10:19:58.502339 23389 net.cpp:408] loss_bbox -> loss_bbox
I0628 10:19:58.502398 23389 net.cpp:150] Setting up loss_bbox
I0628 10:19:58.502403 23389 net.cpp:157] Top shape: (1)
I0628 10:19:58.502404 23389 net.cpp:160]     with loss weight 1
I0628 10:19:58.502408 23389 net.cpp:165] Memory required for data: 23961500
I0628 10:19:58.502409 23389 layer_factory.hpp:77] Creating layer loss_ort
I0628 10:19:58.502413 23389 net.cpp:100] Creating Layer loss_ort
I0628 10:19:58.502415 23389 net.cpp:434] loss_ort <- ort_pred
I0628 10:19:58.502418 23389 net.cpp:434] loss_ort <- ort_targets
I0628 10:19:58.502420 23389 net.cpp:434] loss_ort <- ort_loss_weights
I0628 10:19:58.502424 23389 net.cpp:408] loss_ort -> loss_ort
I0628 10:19:58.502475 23389 net.cpp:150] Setting up loss_ort
I0628 10:19:58.502478 23389 net.cpp:157] Top shape: (1)
I0628 10:19:58.502480 23389 net.cpp:160]     with loss weight 1
I0628 10:19:58.502483 23389 net.cpp:165] Memory required for data: 23961504
I0628 10:19:58.502485 23389 net.cpp:226] loss_ort needs backward computation.
I0628 10:19:58.502488 23389 net.cpp:226] loss_bbox needs backward computation.
I0628 10:19:58.502491 23389 net.cpp:226] loss_cls needs backward computation.
I0628 10:19:58.502494 23389 net.cpp:226] ort_pred needs backward computation.
I0628 10:19:58.502496 23389 net.cpp:226] bbox_pred needs backward computation.
I0628 10:19:58.502499 23389 net.cpp:226] cls_score needs backward computation.
I0628 10:19:58.502501 23389 net.cpp:226] fc7_output_fc7_output_0_split needs backward computation.
I0628 10:19:58.502503 23389 net.cpp:226] fc7_output needs backward computation.
I0628 10:19:58.502506 23389 net.cpp:226] drop7_context needs backward computation.
I0628 10:19:58.502508 23389 net.cpp:226] relu7_context needs backward computation.
I0628 10:19:58.502511 23389 net.cpp:226] fc7_context needs backward computation.
I0628 10:19:58.502513 23389 net.cpp:226] drop6_context needs backward computation.
I0628 10:19:58.502516 23389 net.cpp:226] relu6_context needs backward computation.
I0628 10:19:58.502517 23389 net.cpp:226] fc6_context needs backward computation.
I0628 10:19:58.502529 23389 net.cpp:226] roi_pool5_context needs backward computation.
I0628 10:19:58.502532 23389 net.cpp:226] drop7 needs backward computation.
I0628 10:19:58.502535 23389 net.cpp:226] relu7 needs backward computation.
I0628 10:19:58.502537 23389 net.cpp:226] fc7 needs backward computation.
I0628 10:19:58.502539 23389 net.cpp:226] drop6 needs backward computation.
I0628 10:19:58.502542 23389 net.cpp:226] relu6 needs backward computation.
I0628 10:19:58.502544 23389 net.cpp:226] fc6 needs backward computation.
I0628 10:19:58.502547 23389 net.cpp:226] roi_pool5 needs backward computation.
I0628 10:19:58.502550 23389 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0628 10:19:58.502552 23389 net.cpp:226] relu5_3 needs backward computation.
I0628 10:19:58.502555 23389 net.cpp:226] conv5_3 needs backward computation.
I0628 10:19:58.502557 23389 net.cpp:226] relu5_2 needs backward computation.
I0628 10:19:58.502560 23389 net.cpp:226] conv5_2 needs backward computation.
I0628 10:19:58.502562 23389 net.cpp:226] relu5_1 needs backward computation.
I0628 10:19:58.502564 23389 net.cpp:226] conv5_1 needs backward computation.
I0628 10:19:58.502568 23389 net.cpp:226] pool4 needs backward computation.
I0628 10:19:58.502569 23389 net.cpp:226] relu4_3 needs backward computation.
I0628 10:19:58.502573 23389 net.cpp:226] conv4_3 needs backward computation.
I0628 10:19:58.502574 23389 net.cpp:226] relu4_2 needs backward computation.
I0628 10:19:58.502578 23389 net.cpp:226] conv4_2 needs backward computation.
I0628 10:19:58.502579 23389 net.cpp:226] relu4_1 needs backward computation.
I0628 10:19:58.502581 23389 net.cpp:226] conv4_1 needs backward computation.
I0628 10:19:58.502583 23389 net.cpp:226] pool3 needs backward computation.
I0628 10:19:58.502586 23389 net.cpp:226] relu3_3 needs backward computation.
I0628 10:19:58.502588 23389 net.cpp:226] conv3_3 needs backward computation.
I0628 10:19:58.502590 23389 net.cpp:226] relu3_2 needs backward computation.
I0628 10:19:58.502593 23389 net.cpp:226] conv3_2 needs backward computation.
I0628 10:19:58.502595 23389 net.cpp:226] relu3_1 needs backward computation.
I0628 10:19:58.502598 23389 net.cpp:226] conv3_1 needs backward computation.
I0628 10:19:58.502600 23389 net.cpp:228] pool2 does not need backward computation.
I0628 10:19:58.502604 23389 net.cpp:228] relu2_2 does not need backward computation.
I0628 10:19:58.502605 23389 net.cpp:228] conv2_2 does not need backward computation.
I0628 10:19:58.502609 23389 net.cpp:228] relu2_1 does not need backward computation.
I0628 10:19:58.502610 23389 net.cpp:228] conv2_1 does not need backward computation.
I0628 10:19:58.502614 23389 net.cpp:228] pool1 does not need backward computation.
I0628 10:19:58.502615 23389 net.cpp:228] relu1_2 does not need backward computation.
I0628 10:19:58.502619 23389 net.cpp:228] conv1_2 does not need backward computation.
I0628 10:19:58.502620 23389 net.cpp:228] relu1_1 does not need backward computation.
I0628 10:19:58.502622 23389 net.cpp:228] conv1_1 does not need backward computation.
I0628 10:19:58.502625 23389 net.cpp:228] multi_rois does not need backward computation.
I0628 10:19:58.502629 23389 net.cpp:228] rois_data_1_split does not need backward computation.
I0628 10:19:58.502632 23389 net.cpp:228] data does not need backward computation.
I0628 10:19:58.502635 23389 net.cpp:270] This network produces output loss_bbox
I0628 10:19:58.502637 23389 net.cpp:270] This network produces output loss_cls
I0628 10:19:58.502640 23389 net.cpp:270] This network produces output loss_ort
I0628 10:19:58.502665 23389 net.cpp:283] Network initialization done.
I0628 10:19:58.502815 23389 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0628 10:19:58.818117 23389 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/VGG16.v2.caffemodel
I0628 10:19:58.818128 23389 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0628 10:19:58.818130 23389 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0628 10:19:58.827852 23389 net.cpp:761] Ignoring source layer pool5
I0628 10:19:58.904362 23389 net.cpp:761] Ignoring source layer fc8
I0628 10:19:58.904379 23389 net.cpp:761] Ignoring source layer prob
Solving...
F0628 10:19:59.014564 23389 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
./kitti/scripts/kitti_car_vgg16.sh: line 16: 23389 Aborted                 (core dumped) ./tools/train_net.py --gpu $1 --solver kitti/models/kitti_car/VGG16/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb kitti_car_train --cfg kitti/cfgs/kitti_car_$2.yml
