+ echo Logging output to kitti/logs/kitti_car_3DOP_top2K_vgg16.txt.2018-02-22_17-07-57
Logging output to kitti/logs/kitti_car_3DOP_top2K_vgg16.txt.2018-02-22_17-07-57
+ ./tools/train_net.py --gpu 0 --solver kitti/models/kitti_car/VGG16/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb kitti_car_train --cfg kitti/cfgs/kitti_car_3DOP_top2K.yml
Called with args:
Namespace(cfg_file='kitti/cfgs/kitti_car_3DOP_top2K.yml', gpu_id=0, imdb_name='kitti_car_train', max_iters=40000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, solver='kitti/models/kitti_car/VGG16/solver.prototxt')
Using config:
{'BOX_NUM': 200,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'kitti_car_3DOP_top2K',
 'PIXEL_MEANS': array([[[95.8814, 98.7743, 93.8549]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/rajatmittal/Documents/stereo-image-paper-implementation/3DOP_code_cuDNNv5/frcn-kitti',
 'TEST': {'BBOX_REG': True,
          'MAX_SIZE': 5000,
          'NMS': 0.4,
          'ORT_REG': True,
          'PROPOSAL_METHOD': '3DOP',
          'SCALES': [1295],
          'SVM': False},
 'TRAIN': {'BATCH_SIZE': 1,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.7,
           'BG_THRESH_HI': 0.7,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.7,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 5000,
           'ORT_REG': True,
           'ORT_THRESH': 0.7,
           'PROPOSAL_METHOD': '3DOP',
           'SCALES': [1295],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False}}
/home/rajatmittal/Documents/stereo-image-paper-implementation/3DOP_code_cuDNNv5/frcn-kitti/tools/../lib/datasets/../../data/kitti/object/training
Loaded dataset `kitti_car_train` for training
Appending horizontally-flipped training examples...
kitti_car_train gt roidb loaded from /home/rajatmittal/Documents/stereo-image-paper-implementation/3DOP_code_cuDNNv5/frcn-kitti/data/cache/kitti_car_train_gt_roidb.pkl
Loading 3DOP boxes
1 / 3712
1001 / 3712
2001 / 3712
3001 / 3712
wrote 3DOP roidb to /home/rajatmittal/Documents/stereo-image-paper-implementation/3DOP_code_cuDNNv5/frcn-kitti/data/cache/kitti_car_train_3DOP_top200_roidb.pkl
done
Preparing training data...
done
Output will be saved to `/home/rajatmittal/Documents/stereo-image-paper-implementation/3DOP_code_cuDNNv5/frcn-kitti/output/kitti_car_3DOP_top2K/kitti_car_train`
Filtered 2330 roidb entries: 7424 -> 5094
Computing bounding-box regression targets...
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0222 17:08:08.251751 31885 solver.cpp:48] Initializing solver from parameters: 
train_net: "kitti/models/kitti_car/VGG16/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 30000
snapshot: 0
snapshot_prefix: "vgg16_frcn_kitti"
average_loss: 100
I0222 17:08:08.251776 31885 solver.cpp:81] Creating training net from train_net file: kitti/models/kitti_car/VGG16/train.prototxt
I0222 17:08:08.252290 31885 net.cpp:58] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_loss_weights"
  top: "ort_targets"
  top: "ort_loss_weights"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "multi_rois"
  type: "Python"
  bottom: "rois"
  top: "context"
  python_param {
    module: "roi_data_layer.layer"
    layer: "MultiRoIDataLayer"
    param_str: "\'context\': 1.5"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "roi_pool5_context"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "context"
  top: "pool5_context"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6_context"
  type: "InnerProduct"
  bottom: "pool5_context"
  top: "fc6_context"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6_context"
  type: "ReLU"
  bottom: "fc6_context"
  top: "fc6_context"
}
layer {
  name: "drop6_context"
  type: "Dropout"
  bottom: "fc6_context"
  top: "fc6_context"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_context"
  type: "InnerProduct"
  bottom: "fc6_context"
  top: "fc7_context"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7_context"
  type: "ReLU"
  bottom: "fc7_context"
  top: "fc7_context"
}
layer {
  name: "drop7_context"
  type: "Dropout"
  bottom: "fc7_context"
  top: "fc7_context"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_output"
  type: "Concat"
  bottom: "fc7"
  bottom: "fc7_context"
  top: "fc7_output"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7_output"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7_output"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ort_pred"
  type: "InnerProduct"
  bottom: "fc7_output"
  top: "ort_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_loss_weights"
  top: "loss_bbox"
  loss_weight: 1
}
layer {
  name: "loss_ort"
  type: "SmoothL1Loss"
  bottom: "ort_pred"
  bottom: "ort_targets"
  bottom: "ort_loss_weights"
  top: "loss_ort"
  loss_weight: 1
}
I0222 17:08:08.252461 31885 layer_factory.hpp:77] Creating layer data
I0222 17:08:08.252840 31885 net.cpp:100] Creating Layer data
I0222 17:08:08.252851 31885 net.cpp:408] data -> data
I0222 17:08:08.252858 31885 net.cpp:408] data -> rois
I0222 17:08:08.252863 31885 net.cpp:408] data -> labels
I0222 17:08:08.252868 31885 net.cpp:408] data -> bbox_targets
I0222 17:08:08.252872 31885 net.cpp:408] data -> bbox_loss_weights
I0222 17:08:08.252877 31885 net.cpp:408] data -> ort_targets
I0222 17:08:08.252882 31885 net.cpp:408] data -> ort_loss_weights
I0222 17:08:08.270510 31885 net.cpp:150] Setting up data
I0222 17:08:08.270531 31885 net.cpp:157] Top shape: 1 3 100 100 (30000)
I0222 17:08:08.270535 31885 net.cpp:157] Top shape: 1 5 (5)
I0222 17:08:08.270537 31885 net.cpp:157] Top shape: 1 (1)
I0222 17:08:08.270539 31885 net.cpp:157] Top shape: 1 8 (8)
I0222 17:08:08.270542 31885 net.cpp:157] Top shape: 1 8 (8)
I0222 17:08:08.270545 31885 net.cpp:157] Top shape: 1 2 (2)
I0222 17:08:08.270547 31885 net.cpp:157] Top shape: 1 2 (2)
I0222 17:08:08.270548 31885 net.cpp:165] Memory required for data: 120104
I0222 17:08:08.270555 31885 layer_factory.hpp:77] Creating layer rois_data_1_split
I0222 17:08:08.270565 31885 net.cpp:100] Creating Layer rois_data_1_split
I0222 17:08:08.270568 31885 net.cpp:434] rois_data_1_split <- rois
I0222 17:08:08.270575 31885 net.cpp:408] rois_data_1_split -> rois_data_1_split_0
I0222 17:08:08.270581 31885 net.cpp:408] rois_data_1_split -> rois_data_1_split_1
I0222 17:08:08.270623 31885 net.cpp:150] Setting up rois_data_1_split
I0222 17:08:08.270627 31885 net.cpp:157] Top shape: 1 5 (5)
I0222 17:08:08.270629 31885 net.cpp:157] Top shape: 1 5 (5)
I0222 17:08:08.270632 31885 net.cpp:165] Memory required for data: 120144
I0222 17:08:08.270633 31885 layer_factory.hpp:77] Creating layer multi_rois
I0222 17:08:08.270664 31885 net.cpp:100] Creating Layer multi_rois
I0222 17:08:08.270668 31885 net.cpp:434] multi_rois <- rois_data_1_split_0
I0222 17:08:08.270671 31885 net.cpp:408] multi_rois -> context
'context': 1.5
I0222 17:08:08.271029 31885 net.cpp:150] Setting up multi_rois
I0222 17:08:08.271037 31885 net.cpp:157] Top shape: 1 5 (5)
I0222 17:08:08.271040 31885 net.cpp:165] Memory required for data: 120164
I0222 17:08:08.271044 31885 layer_factory.hpp:77] Creating layer conv1_1
I0222 17:08:08.271051 31885 net.cpp:100] Creating Layer conv1_1
I0222 17:08:08.271054 31885 net.cpp:434] conv1_1 <- data
I0222 17:08:08.271059 31885 net.cpp:408] conv1_1 -> conv1_1
I0222 17:08:08.272694 31885 net.cpp:150] Setting up conv1_1
I0222 17:08:08.272706 31885 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0222 17:08:08.272724 31885 net.cpp:165] Memory required for data: 2680164
I0222 17:08:08.272734 31885 layer_factory.hpp:77] Creating layer relu1_1
I0222 17:08:08.272743 31885 net.cpp:100] Creating Layer relu1_1
I0222 17:08:08.272747 31885 net.cpp:434] relu1_1 <- conv1_1
I0222 17:08:08.272750 31885 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0222 17:08:08.272755 31885 net.cpp:150] Setting up relu1_1
I0222 17:08:08.272758 31885 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0222 17:08:08.272760 31885 net.cpp:165] Memory required for data: 5240164
I0222 17:08:08.272763 31885 layer_factory.hpp:77] Creating layer conv1_2
I0222 17:08:08.272770 31885 net.cpp:100] Creating Layer conv1_2
I0222 17:08:08.272773 31885 net.cpp:434] conv1_2 <- conv1_1
I0222 17:08:08.272776 31885 net.cpp:408] conv1_2 -> conv1_2
I0222 17:08:08.273653 31885 net.cpp:150] Setting up conv1_2
I0222 17:08:08.273663 31885 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0222 17:08:08.273680 31885 net.cpp:165] Memory required for data: 7800164
I0222 17:08:08.273689 31885 layer_factory.hpp:77] Creating layer relu1_2
I0222 17:08:08.273694 31885 net.cpp:100] Creating Layer relu1_2
I0222 17:08:08.273696 31885 net.cpp:434] relu1_2 <- conv1_2
I0222 17:08:08.273700 31885 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0222 17:08:08.273705 31885 net.cpp:150] Setting up relu1_2
I0222 17:08:08.273707 31885 net.cpp:157] Top shape: 1 64 100 100 (640000)
I0222 17:08:08.273710 31885 net.cpp:165] Memory required for data: 10360164
I0222 17:08:08.273712 31885 layer_factory.hpp:77] Creating layer pool1
I0222 17:08:08.273717 31885 net.cpp:100] Creating Layer pool1
I0222 17:08:08.273720 31885 net.cpp:434] pool1 <- conv1_2
I0222 17:08:08.273723 31885 net.cpp:408] pool1 -> pool1
I0222 17:08:08.273751 31885 net.cpp:150] Setting up pool1
I0222 17:08:08.273754 31885 net.cpp:157] Top shape: 1 64 50 50 (160000)
I0222 17:08:08.273756 31885 net.cpp:165] Memory required for data: 11000164
I0222 17:08:08.273758 31885 layer_factory.hpp:77] Creating layer conv2_1
I0222 17:08:08.273766 31885 net.cpp:100] Creating Layer conv2_1
I0222 17:08:08.273768 31885 net.cpp:434] conv2_1 <- pool1
I0222 17:08:08.273774 31885 net.cpp:408] conv2_1 -> conv2_1
I0222 17:08:08.274663 31885 net.cpp:150] Setting up conv2_1
I0222 17:08:08.274674 31885 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0222 17:08:08.274677 31885 net.cpp:165] Memory required for data: 12280164
I0222 17:08:08.274682 31885 layer_factory.hpp:77] Creating layer relu2_1
I0222 17:08:08.274688 31885 net.cpp:100] Creating Layer relu2_1
I0222 17:08:08.274691 31885 net.cpp:434] relu2_1 <- conv2_1
I0222 17:08:08.274695 31885 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0222 17:08:08.274699 31885 net.cpp:150] Setting up relu2_1
I0222 17:08:08.274703 31885 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0222 17:08:08.274704 31885 net.cpp:165] Memory required for data: 13560164
I0222 17:08:08.274706 31885 layer_factory.hpp:77] Creating layer conv2_2
I0222 17:08:08.274711 31885 net.cpp:100] Creating Layer conv2_2
I0222 17:08:08.274713 31885 net.cpp:434] conv2_2 <- conv2_1
I0222 17:08:08.274718 31885 net.cpp:408] conv2_2 -> conv2_2
I0222 17:08:08.274942 31885 net.cpp:150] Setting up conv2_2
I0222 17:08:08.274948 31885 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0222 17:08:08.274950 31885 net.cpp:165] Memory required for data: 14840164
I0222 17:08:08.274955 31885 layer_factory.hpp:77] Creating layer relu2_2
I0222 17:08:08.274958 31885 net.cpp:100] Creating Layer relu2_2
I0222 17:08:08.274960 31885 net.cpp:434] relu2_2 <- conv2_2
I0222 17:08:08.274965 31885 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0222 17:08:08.274968 31885 net.cpp:150] Setting up relu2_2
I0222 17:08:08.274971 31885 net.cpp:157] Top shape: 1 128 50 50 (320000)
I0222 17:08:08.274973 31885 net.cpp:165] Memory required for data: 16120164
I0222 17:08:08.274976 31885 layer_factory.hpp:77] Creating layer pool2
I0222 17:08:08.274979 31885 net.cpp:100] Creating Layer pool2
I0222 17:08:08.274982 31885 net.cpp:434] pool2 <- conv2_2
I0222 17:08:08.274986 31885 net.cpp:408] pool2 -> pool2
I0222 17:08:08.275012 31885 net.cpp:150] Setting up pool2
I0222 17:08:08.275018 31885 net.cpp:157] Top shape: 1 128 25 25 (80000)
I0222 17:08:08.275020 31885 net.cpp:165] Memory required for data: 16440164
I0222 17:08:08.275022 31885 layer_factory.hpp:77] Creating layer conv3_1
I0222 17:08:08.275027 31885 net.cpp:100] Creating Layer conv3_1
I0222 17:08:08.275029 31885 net.cpp:434] conv3_1 <- pool2
I0222 17:08:08.275034 31885 net.cpp:408] conv3_1 -> conv3_1
I0222 17:08:08.276016 31885 net.cpp:150] Setting up conv3_1
I0222 17:08:08.276027 31885 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0222 17:08:08.276031 31885 net.cpp:165] Memory required for data: 17080164
I0222 17:08:08.276037 31885 layer_factory.hpp:77] Creating layer relu3_1
I0222 17:08:08.276042 31885 net.cpp:100] Creating Layer relu3_1
I0222 17:08:08.276044 31885 net.cpp:434] relu3_1 <- conv3_1
I0222 17:08:08.276049 31885 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0222 17:08:08.276053 31885 net.cpp:150] Setting up relu3_1
I0222 17:08:08.276057 31885 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0222 17:08:08.276058 31885 net.cpp:165] Memory required for data: 17720164
I0222 17:08:08.276060 31885 layer_factory.hpp:77] Creating layer conv3_2
I0222 17:08:08.276067 31885 net.cpp:100] Creating Layer conv3_2
I0222 17:08:08.276068 31885 net.cpp:434] conv3_2 <- conv3_1
I0222 17:08:08.276073 31885 net.cpp:408] conv3_2 -> conv3_2
I0222 17:08:08.277281 31885 net.cpp:150] Setting up conv3_2
I0222 17:08:08.277292 31885 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0222 17:08:08.277293 31885 net.cpp:165] Memory required for data: 18360164
I0222 17:08:08.277298 31885 layer_factory.hpp:77] Creating layer relu3_2
I0222 17:08:08.277307 31885 net.cpp:100] Creating Layer relu3_2
I0222 17:08:08.277309 31885 net.cpp:434] relu3_2 <- conv3_2
I0222 17:08:08.277313 31885 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0222 17:08:08.277318 31885 net.cpp:150] Setting up relu3_2
I0222 17:08:08.277320 31885 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0222 17:08:08.277323 31885 net.cpp:165] Memory required for data: 19000164
I0222 17:08:08.277324 31885 layer_factory.hpp:77] Creating layer conv3_3
I0222 17:08:08.277330 31885 net.cpp:100] Creating Layer conv3_3
I0222 17:08:08.277333 31885 net.cpp:434] conv3_3 <- conv3_2
I0222 17:08:08.277336 31885 net.cpp:408] conv3_3 -> conv3_3
I0222 17:08:08.278574 31885 net.cpp:150] Setting up conv3_3
I0222 17:08:08.278585 31885 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0222 17:08:08.278589 31885 net.cpp:165] Memory required for data: 19640164
I0222 17:08:08.278592 31885 layer_factory.hpp:77] Creating layer relu3_3
I0222 17:08:08.278597 31885 net.cpp:100] Creating Layer relu3_3
I0222 17:08:08.278600 31885 net.cpp:434] relu3_3 <- conv3_3
I0222 17:08:08.278604 31885 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0222 17:08:08.278609 31885 net.cpp:150] Setting up relu3_3
I0222 17:08:08.278612 31885 net.cpp:157] Top shape: 1 256 25 25 (160000)
I0222 17:08:08.278614 31885 net.cpp:165] Memory required for data: 20280164
I0222 17:08:08.278616 31885 layer_factory.hpp:77] Creating layer pool3
I0222 17:08:08.278622 31885 net.cpp:100] Creating Layer pool3
I0222 17:08:08.278625 31885 net.cpp:434] pool3 <- conv3_3
I0222 17:08:08.278627 31885 net.cpp:408] pool3 -> pool3
I0222 17:08:08.278656 31885 net.cpp:150] Setting up pool3
I0222 17:08:08.278663 31885 net.cpp:157] Top shape: 1 256 13 13 (43264)
I0222 17:08:08.278666 31885 net.cpp:165] Memory required for data: 20453220
I0222 17:08:08.278667 31885 layer_factory.hpp:77] Creating layer conv4_1
I0222 17:08:08.278674 31885 net.cpp:100] Creating Layer conv4_1
I0222 17:08:08.278676 31885 net.cpp:434] conv4_1 <- pool3
I0222 17:08:08.278681 31885 net.cpp:408] conv4_1 -> conv4_1
I0222 17:08:08.280812 31885 net.cpp:150] Setting up conv4_1
I0222 17:08:08.280827 31885 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0222 17:08:08.280830 31885 net.cpp:165] Memory required for data: 20799332
I0222 17:08:08.280836 31885 layer_factory.hpp:77] Creating layer relu4_1
I0222 17:08:08.280843 31885 net.cpp:100] Creating Layer relu4_1
I0222 17:08:08.280845 31885 net.cpp:434] relu4_1 <- conv4_1
I0222 17:08:08.280851 31885 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0222 17:08:08.280858 31885 net.cpp:150] Setting up relu4_1
I0222 17:08:08.280860 31885 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0222 17:08:08.280863 31885 net.cpp:165] Memory required for data: 21145444
I0222 17:08:08.280864 31885 layer_factory.hpp:77] Creating layer conv4_2
I0222 17:08:08.280870 31885 net.cpp:100] Creating Layer conv4_2
I0222 17:08:08.280872 31885 net.cpp:434] conv4_2 <- conv4_1
I0222 17:08:08.280877 31885 net.cpp:408] conv4_2 -> conv4_2
I0222 17:08:08.284780 31885 net.cpp:150] Setting up conv4_2
I0222 17:08:08.284816 31885 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0222 17:08:08.284819 31885 net.cpp:165] Memory required for data: 21491556
I0222 17:08:08.284832 31885 layer_factory.hpp:77] Creating layer relu4_2
I0222 17:08:08.284840 31885 net.cpp:100] Creating Layer relu4_2
I0222 17:08:08.284843 31885 net.cpp:434] relu4_2 <- conv4_2
I0222 17:08:08.284850 31885 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0222 17:08:08.284858 31885 net.cpp:150] Setting up relu4_2
I0222 17:08:08.284862 31885 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0222 17:08:08.284862 31885 net.cpp:165] Memory required for data: 21837668
I0222 17:08:08.284864 31885 layer_factory.hpp:77] Creating layer conv4_3
I0222 17:08:08.284871 31885 net.cpp:100] Creating Layer conv4_3
I0222 17:08:08.284873 31885 net.cpp:434] conv4_3 <- conv4_2
I0222 17:08:08.284880 31885 net.cpp:408] conv4_3 -> conv4_3
I0222 17:08:08.288697 31885 net.cpp:150] Setting up conv4_3
I0222 17:08:08.288717 31885 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0222 17:08:08.288719 31885 net.cpp:165] Memory required for data: 22183780
I0222 17:08:08.288727 31885 layer_factory.hpp:77] Creating layer relu4_3
I0222 17:08:08.288736 31885 net.cpp:100] Creating Layer relu4_3
I0222 17:08:08.288740 31885 net.cpp:434] relu4_3 <- conv4_3
I0222 17:08:08.288745 31885 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0222 17:08:08.288753 31885 net.cpp:150] Setting up relu4_3
I0222 17:08:08.288755 31885 net.cpp:157] Top shape: 1 512 13 13 (86528)
I0222 17:08:08.288758 31885 net.cpp:165] Memory required for data: 22529892
I0222 17:08:08.288759 31885 layer_factory.hpp:77] Creating layer pool4
I0222 17:08:08.288764 31885 net.cpp:100] Creating Layer pool4
I0222 17:08:08.288765 31885 net.cpp:434] pool4 <- conv4_3
I0222 17:08:08.288771 31885 net.cpp:408] pool4 -> pool4
I0222 17:08:08.288801 31885 net.cpp:150] Setting up pool4
I0222 17:08:08.288806 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.288807 31885 net.cpp:165] Memory required for data: 22630244
I0222 17:08:08.288810 31885 layer_factory.hpp:77] Creating layer conv5_1
I0222 17:08:08.288818 31885 net.cpp:100] Creating Layer conv5_1
I0222 17:08:08.288822 31885 net.cpp:434] conv5_1 <- pool4
I0222 17:08:08.288828 31885 net.cpp:408] conv5_1 -> conv5_1
I0222 17:08:08.292673 31885 net.cpp:150] Setting up conv5_1
I0222 17:08:08.292696 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.292699 31885 net.cpp:165] Memory required for data: 22730596
I0222 17:08:08.292706 31885 layer_factory.hpp:77] Creating layer relu5_1
I0222 17:08:08.292714 31885 net.cpp:100] Creating Layer relu5_1
I0222 17:08:08.292717 31885 net.cpp:434] relu5_1 <- conv5_1
I0222 17:08:08.292723 31885 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0222 17:08:08.292731 31885 net.cpp:150] Setting up relu5_1
I0222 17:08:08.292733 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.292735 31885 net.cpp:165] Memory required for data: 22830948
I0222 17:08:08.292737 31885 layer_factory.hpp:77] Creating layer conv5_2
I0222 17:08:08.292747 31885 net.cpp:100] Creating Layer conv5_2
I0222 17:08:08.292749 31885 net.cpp:434] conv5_2 <- conv5_1
I0222 17:08:08.292753 31885 net.cpp:408] conv5_2 -> conv5_2
I0222 17:08:08.296651 31885 net.cpp:150] Setting up conv5_2
I0222 17:08:08.296672 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.296674 31885 net.cpp:165] Memory required for data: 22931300
I0222 17:08:08.296682 31885 layer_factory.hpp:77] Creating layer relu5_2
I0222 17:08:08.296691 31885 net.cpp:100] Creating Layer relu5_2
I0222 17:08:08.296694 31885 net.cpp:434] relu5_2 <- conv5_2
I0222 17:08:08.296700 31885 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0222 17:08:08.296707 31885 net.cpp:150] Setting up relu5_2
I0222 17:08:08.296710 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.296711 31885 net.cpp:165] Memory required for data: 23031652
I0222 17:08:08.296713 31885 layer_factory.hpp:77] Creating layer conv5_3
I0222 17:08:08.296722 31885 net.cpp:100] Creating Layer conv5_3
I0222 17:08:08.296725 31885 net.cpp:434] conv5_3 <- conv5_2
I0222 17:08:08.296731 31885 net.cpp:408] conv5_3 -> conv5_3
I0222 17:08:08.300730 31885 net.cpp:150] Setting up conv5_3
I0222 17:08:08.300770 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.300772 31885 net.cpp:165] Memory required for data: 23132004
I0222 17:08:08.300779 31885 layer_factory.hpp:77] Creating layer relu5_3
I0222 17:08:08.300796 31885 net.cpp:100] Creating Layer relu5_3
I0222 17:08:08.300799 31885 net.cpp:434] relu5_3 <- conv5_3
I0222 17:08:08.300804 31885 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0222 17:08:08.300812 31885 net.cpp:150] Setting up relu5_3
I0222 17:08:08.300814 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.300817 31885 net.cpp:165] Memory required for data: 23232356
I0222 17:08:08.300818 31885 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0222 17:08:08.300823 31885 net.cpp:100] Creating Layer conv5_3_relu5_3_0_split
I0222 17:08:08.300825 31885 net.cpp:434] conv5_3_relu5_3_0_split <- conv5_3
I0222 17:08:08.300829 31885 net.cpp:408] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0222 17:08:08.300834 31885 net.cpp:408] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0222 17:08:08.300865 31885 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0222 17:08:08.300870 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.300873 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.300874 31885 net.cpp:165] Memory required for data: 23433060
I0222 17:08:08.300876 31885 layer_factory.hpp:77] Creating layer roi_pool5
I0222 17:08:08.300884 31885 net.cpp:100] Creating Layer roi_pool5
I0222 17:08:08.300885 31885 net.cpp:434] roi_pool5 <- conv5_3_relu5_3_0_split_0
I0222 17:08:08.300889 31885 net.cpp:434] roi_pool5 <- rois_data_1_split_1
I0222 17:08:08.300894 31885 net.cpp:408] roi_pool5 -> pool5
I0222 17:08:08.300899 31885 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0222 17:08:08.300931 31885 net.cpp:150] Setting up roi_pool5
I0222 17:08:08.300935 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.300937 31885 net.cpp:165] Memory required for data: 23533412
I0222 17:08:08.300940 31885 layer_factory.hpp:77] Creating layer fc6
I0222 17:08:08.300945 31885 net.cpp:100] Creating Layer fc6
I0222 17:08:08.300947 31885 net.cpp:434] fc6 <- pool5
I0222 17:08:08.300952 31885 net.cpp:408] fc6 -> fc6
I0222 17:08:08.466385 31885 net.cpp:150] Setting up fc6
I0222 17:08:08.466409 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.466411 31885 net.cpp:165] Memory required for data: 23549796
I0222 17:08:08.466419 31885 layer_factory.hpp:77] Creating layer relu6
I0222 17:08:08.466428 31885 net.cpp:100] Creating Layer relu6
I0222 17:08:08.466433 31885 net.cpp:434] relu6 <- fc6
I0222 17:08:08.466439 31885 net.cpp:395] relu6 -> fc6 (in-place)
I0222 17:08:08.466446 31885 net.cpp:150] Setting up relu6
I0222 17:08:08.466449 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.466451 31885 net.cpp:165] Memory required for data: 23566180
I0222 17:08:08.466454 31885 layer_factory.hpp:77] Creating layer drop6
I0222 17:08:08.466457 31885 net.cpp:100] Creating Layer drop6
I0222 17:08:08.466460 31885 net.cpp:434] drop6 <- fc6
I0222 17:08:08.466464 31885 net.cpp:395] drop6 -> fc6 (in-place)
I0222 17:08:08.466478 31885 net.cpp:150] Setting up drop6
I0222 17:08:08.466481 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.466483 31885 net.cpp:165] Memory required for data: 23582564
I0222 17:08:08.466485 31885 layer_factory.hpp:77] Creating layer fc7
I0222 17:08:08.466492 31885 net.cpp:100] Creating Layer fc7
I0222 17:08:08.466495 31885 net.cpp:434] fc7 <- fc6
I0222 17:08:08.466498 31885 net.cpp:408] fc7 -> fc7
I0222 17:08:08.494099 31885 net.cpp:150] Setting up fc7
I0222 17:08:08.494119 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.494122 31885 net.cpp:165] Memory required for data: 23598948
I0222 17:08:08.494130 31885 layer_factory.hpp:77] Creating layer relu7
I0222 17:08:08.494138 31885 net.cpp:100] Creating Layer relu7
I0222 17:08:08.494143 31885 net.cpp:434] relu7 <- fc7
I0222 17:08:08.494148 31885 net.cpp:395] relu7 -> fc7 (in-place)
I0222 17:08:08.494154 31885 net.cpp:150] Setting up relu7
I0222 17:08:08.494158 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.494158 31885 net.cpp:165] Memory required for data: 23615332
I0222 17:08:08.494160 31885 layer_factory.hpp:77] Creating layer drop7
I0222 17:08:08.494168 31885 net.cpp:100] Creating Layer drop7
I0222 17:08:08.494169 31885 net.cpp:434] drop7 <- fc7
I0222 17:08:08.494173 31885 net.cpp:395] drop7 -> fc7 (in-place)
I0222 17:08:08.494189 31885 net.cpp:150] Setting up drop7
I0222 17:08:08.494192 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.494194 31885 net.cpp:165] Memory required for data: 23631716
I0222 17:08:08.494196 31885 layer_factory.hpp:77] Creating layer roi_pool5_context
I0222 17:08:08.494201 31885 net.cpp:100] Creating Layer roi_pool5_context
I0222 17:08:08.494204 31885 net.cpp:434] roi_pool5_context <- conv5_3_relu5_3_0_split_1
I0222 17:08:08.494208 31885 net.cpp:434] roi_pool5_context <- context
I0222 17:08:08.494213 31885 net.cpp:408] roi_pool5_context -> pool5_context
I0222 17:08:08.494223 31885 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0222 17:08:08.494261 31885 net.cpp:150] Setting up roi_pool5_context
I0222 17:08:08.494266 31885 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0222 17:08:08.494266 31885 net.cpp:165] Memory required for data: 23732068
I0222 17:08:08.494268 31885 layer_factory.hpp:77] Creating layer fc6_context
I0222 17:08:08.494274 31885 net.cpp:100] Creating Layer fc6_context
I0222 17:08:08.494277 31885 net.cpp:434] fc6_context <- pool5_context
I0222 17:08:08.494280 31885 net.cpp:408] fc6_context -> fc6_context
I0222 17:08:08.659710 31885 net.cpp:150] Setting up fc6_context
I0222 17:08:08.659751 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.659754 31885 net.cpp:165] Memory required for data: 23748452
I0222 17:08:08.659762 31885 layer_factory.hpp:77] Creating layer relu6_context
I0222 17:08:08.659770 31885 net.cpp:100] Creating Layer relu6_context
I0222 17:08:08.659775 31885 net.cpp:434] relu6_context <- fc6_context
I0222 17:08:08.659780 31885 net.cpp:395] relu6_context -> fc6_context (in-place)
I0222 17:08:08.659787 31885 net.cpp:150] Setting up relu6_context
I0222 17:08:08.659790 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.659792 31885 net.cpp:165] Memory required for data: 23764836
I0222 17:08:08.659795 31885 layer_factory.hpp:77] Creating layer drop6_context
I0222 17:08:08.659798 31885 net.cpp:100] Creating Layer drop6_context
I0222 17:08:08.659801 31885 net.cpp:434] drop6_context <- fc6_context
I0222 17:08:08.659804 31885 net.cpp:395] drop6_context -> fc6_context (in-place)
I0222 17:08:08.659821 31885 net.cpp:150] Setting up drop6_context
I0222 17:08:08.659824 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.659826 31885 net.cpp:165] Memory required for data: 23781220
I0222 17:08:08.659828 31885 layer_factory.hpp:77] Creating layer fc7_context
I0222 17:08:08.659833 31885 net.cpp:100] Creating Layer fc7_context
I0222 17:08:08.659835 31885 net.cpp:434] fc7_context <- fc6_context
I0222 17:08:08.659839 31885 net.cpp:408] fc7_context -> fc7_context
I0222 17:08:08.687227 31885 net.cpp:150] Setting up fc7_context
I0222 17:08:08.687250 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.687252 31885 net.cpp:165] Memory required for data: 23797604
I0222 17:08:08.687269 31885 layer_factory.hpp:77] Creating layer relu7_context
I0222 17:08:08.687278 31885 net.cpp:100] Creating Layer relu7_context
I0222 17:08:08.687281 31885 net.cpp:434] relu7_context <- fc7_context
I0222 17:08:08.687288 31885 net.cpp:395] relu7_context -> fc7_context (in-place)
I0222 17:08:08.687295 31885 net.cpp:150] Setting up relu7_context
I0222 17:08:08.687299 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.687299 31885 net.cpp:165] Memory required for data: 23813988
I0222 17:08:08.687301 31885 layer_factory.hpp:77] Creating layer drop7_context
I0222 17:08:08.687306 31885 net.cpp:100] Creating Layer drop7_context
I0222 17:08:08.687309 31885 net.cpp:434] drop7_context <- fc7_context
I0222 17:08:08.687311 31885 net.cpp:395] drop7_context -> fc7_context (in-place)
I0222 17:08:08.687328 31885 net.cpp:150] Setting up drop7_context
I0222 17:08:08.687331 31885 net.cpp:157] Top shape: 1 4096 (4096)
I0222 17:08:08.687333 31885 net.cpp:165] Memory required for data: 23830372
I0222 17:08:08.687335 31885 layer_factory.hpp:77] Creating layer fc7_output
I0222 17:08:08.687340 31885 net.cpp:100] Creating Layer fc7_output
I0222 17:08:08.687341 31885 net.cpp:434] fc7_output <- fc7
I0222 17:08:08.687345 31885 net.cpp:434] fc7_output <- fc7_context
I0222 17:08:08.687350 31885 net.cpp:408] fc7_output -> fc7_output
I0222 17:08:08.687366 31885 net.cpp:150] Setting up fc7_output
I0222 17:08:08.687368 31885 net.cpp:157] Top shape: 1 8192 (8192)
I0222 17:08:08.687371 31885 net.cpp:165] Memory required for data: 23863140
I0222 17:08:08.687372 31885 layer_factory.hpp:77] Creating layer fc7_output_fc7_output_0_split
I0222 17:08:08.687376 31885 net.cpp:100] Creating Layer fc7_output_fc7_output_0_split
I0222 17:08:08.687378 31885 net.cpp:434] fc7_output_fc7_output_0_split <- fc7_output
I0222 17:08:08.687383 31885 net.cpp:408] fc7_output_fc7_output_0_split -> fc7_output_fc7_output_0_split_0
I0222 17:08:08.687388 31885 net.cpp:408] fc7_output_fc7_output_0_split -> fc7_output_fc7_output_0_split_1
I0222 17:08:08.687392 31885 net.cpp:408] fc7_output_fc7_output_0_split -> fc7_output_fc7_output_0_split_2
I0222 17:08:08.687422 31885 net.cpp:150] Setting up fc7_output_fc7_output_0_split
I0222 17:08:08.687427 31885 net.cpp:157] Top shape: 1 8192 (8192)
I0222 17:08:08.687428 31885 net.cpp:157] Top shape: 1 8192 (8192)
I0222 17:08:08.687430 31885 net.cpp:157] Top shape: 1 8192 (8192)
I0222 17:08:08.687433 31885 net.cpp:165] Memory required for data: 23961444
I0222 17:08:08.687434 31885 layer_factory.hpp:77] Creating layer cls_score
I0222 17:08:08.687440 31885 net.cpp:100] Creating Layer cls_score
I0222 17:08:08.687443 31885 net.cpp:434] cls_score <- fc7_output_fc7_output_0_split_0
I0222 17:08:08.687449 31885 net.cpp:408] cls_score -> cls_score
I0222 17:08:08.687649 31885 net.cpp:150] Setting up cls_score
I0222 17:08:08.687654 31885 net.cpp:157] Top shape: 1 2 (2)
I0222 17:08:08.687656 31885 net.cpp:165] Memory required for data: 23961452
I0222 17:08:08.687660 31885 layer_factory.hpp:77] Creating layer bbox_pred
I0222 17:08:08.687665 31885 net.cpp:100] Creating Layer bbox_pred
I0222 17:08:08.687667 31885 net.cpp:434] bbox_pred <- fc7_output_fc7_output_0_split_1
I0222 17:08:08.687671 31885 net.cpp:408] bbox_pred -> bbox_pred
I0222 17:08:08.688235 31885 net.cpp:150] Setting up bbox_pred
I0222 17:08:08.688241 31885 net.cpp:157] Top shape: 1 8 (8)
I0222 17:08:08.688243 31885 net.cpp:165] Memory required for data: 23961484
I0222 17:08:08.688247 31885 layer_factory.hpp:77] Creating layer ort_pred
I0222 17:08:08.688252 31885 net.cpp:100] Creating Layer ort_pred
I0222 17:08:08.688256 31885 net.cpp:434] ort_pred <- fc7_output_fc7_output_0_split_2
I0222 17:08:08.688259 31885 net.cpp:408] ort_pred -> ort_pred
I0222 17:08:08.688444 31885 net.cpp:150] Setting up ort_pred
I0222 17:08:08.688449 31885 net.cpp:157] Top shape: 1 2 (2)
I0222 17:08:08.688452 31885 net.cpp:165] Memory required for data: 23961492
I0222 17:08:08.688455 31885 layer_factory.hpp:77] Creating layer loss_cls
I0222 17:08:08.688460 31885 net.cpp:100] Creating Layer loss_cls
I0222 17:08:08.688462 31885 net.cpp:434] loss_cls <- cls_score
I0222 17:08:08.688467 31885 net.cpp:434] loss_cls <- labels
I0222 17:08:08.688469 31885 net.cpp:408] loss_cls -> loss_cls
I0222 17:08:08.688475 31885 layer_factory.hpp:77] Creating layer loss_cls
I0222 17:08:08.688531 31885 net.cpp:150] Setting up loss_cls
I0222 17:08:08.688536 31885 net.cpp:157] Top shape: (1)
I0222 17:08:08.688539 31885 net.cpp:160]     with loss weight 1
I0222 17:08:08.688547 31885 net.cpp:165] Memory required for data: 23961496
I0222 17:08:08.688549 31885 layer_factory.hpp:77] Creating layer loss_bbox
I0222 17:08:08.688555 31885 net.cpp:100] Creating Layer loss_bbox
I0222 17:08:08.688556 31885 net.cpp:434] loss_bbox <- bbox_pred
I0222 17:08:08.688560 31885 net.cpp:434] loss_bbox <- bbox_targets
I0222 17:08:08.688562 31885 net.cpp:434] loss_bbox <- bbox_loss_weights
I0222 17:08:08.688570 31885 net.cpp:408] loss_bbox -> loss_bbox
I0222 17:08:08.688606 31885 net.cpp:150] Setting up loss_bbox
I0222 17:08:08.688611 31885 net.cpp:157] Top shape: (1)
I0222 17:08:08.688613 31885 net.cpp:160]     with loss weight 1
I0222 17:08:08.688616 31885 net.cpp:165] Memory required for data: 23961500
I0222 17:08:08.688618 31885 layer_factory.hpp:77] Creating layer loss_ort
I0222 17:08:08.688621 31885 net.cpp:100] Creating Layer loss_ort
I0222 17:08:08.688624 31885 net.cpp:434] loss_ort <- ort_pred
I0222 17:08:08.688627 31885 net.cpp:434] loss_ort <- ort_targets
I0222 17:08:08.688629 31885 net.cpp:434] loss_ort <- ort_loss_weights
I0222 17:08:08.688632 31885 net.cpp:408] loss_ort -> loss_ort
I0222 17:08:08.688665 31885 net.cpp:150] Setting up loss_ort
I0222 17:08:08.688669 31885 net.cpp:157] Top shape: (1)
I0222 17:08:08.688671 31885 net.cpp:160]     with loss weight 1
I0222 17:08:08.688674 31885 net.cpp:165] Memory required for data: 23961504
I0222 17:08:08.688678 31885 net.cpp:226] loss_ort needs backward computation.
I0222 17:08:08.688680 31885 net.cpp:226] loss_bbox needs backward computation.
I0222 17:08:08.688683 31885 net.cpp:226] loss_cls needs backward computation.
I0222 17:08:08.688686 31885 net.cpp:226] ort_pred needs backward computation.
I0222 17:08:08.688688 31885 net.cpp:226] bbox_pred needs backward computation.
I0222 17:08:08.688690 31885 net.cpp:226] cls_score needs backward computation.
I0222 17:08:08.688694 31885 net.cpp:226] fc7_output_fc7_output_0_split needs backward computation.
I0222 17:08:08.688695 31885 net.cpp:226] fc7_output needs backward computation.
I0222 17:08:08.688697 31885 net.cpp:226] drop7_context needs backward computation.
I0222 17:08:08.688700 31885 net.cpp:226] relu7_context needs backward computation.
I0222 17:08:08.688702 31885 net.cpp:226] fc7_context needs backward computation.
I0222 17:08:08.688704 31885 net.cpp:226] drop6_context needs backward computation.
I0222 17:08:08.688706 31885 net.cpp:226] relu6_context needs backward computation.
I0222 17:08:08.688709 31885 net.cpp:226] fc6_context needs backward computation.
I0222 17:08:08.688710 31885 net.cpp:226] roi_pool5_context needs backward computation.
I0222 17:08:08.688714 31885 net.cpp:226] drop7 needs backward computation.
I0222 17:08:08.688716 31885 net.cpp:226] relu7 needs backward computation.
I0222 17:08:08.688719 31885 net.cpp:226] fc7 needs backward computation.
I0222 17:08:08.688721 31885 net.cpp:226] drop6 needs backward computation.
I0222 17:08:08.688724 31885 net.cpp:226] relu6 needs backward computation.
I0222 17:08:08.688725 31885 net.cpp:226] fc6 needs backward computation.
I0222 17:08:08.688727 31885 net.cpp:226] roi_pool5 needs backward computation.
I0222 17:08:08.688730 31885 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0222 17:08:08.688733 31885 net.cpp:226] relu5_3 needs backward computation.
I0222 17:08:08.688735 31885 net.cpp:226] conv5_3 needs backward computation.
I0222 17:08:08.688738 31885 net.cpp:226] relu5_2 needs backward computation.
I0222 17:08:08.688740 31885 net.cpp:226] conv5_2 needs backward computation.
I0222 17:08:08.688742 31885 net.cpp:226] relu5_1 needs backward computation.
I0222 17:08:08.688745 31885 net.cpp:226] conv5_1 needs backward computation.
I0222 17:08:08.688747 31885 net.cpp:226] pool4 needs backward computation.
I0222 17:08:08.688750 31885 net.cpp:226] relu4_3 needs backward computation.
I0222 17:08:08.688752 31885 net.cpp:226] conv4_3 needs backward computation.
I0222 17:08:08.688755 31885 net.cpp:226] relu4_2 needs backward computation.
I0222 17:08:08.688756 31885 net.cpp:226] conv4_2 needs backward computation.
I0222 17:08:08.688760 31885 net.cpp:226] relu4_1 needs backward computation.
I0222 17:08:08.688761 31885 net.cpp:226] conv4_1 needs backward computation.
I0222 17:08:08.688763 31885 net.cpp:226] pool3 needs backward computation.
I0222 17:08:08.688766 31885 net.cpp:226] relu3_3 needs backward computation.
I0222 17:08:08.688768 31885 net.cpp:226] conv3_3 needs backward computation.
I0222 17:08:08.688771 31885 net.cpp:226] relu3_2 needs backward computation.
I0222 17:08:08.688772 31885 net.cpp:226] conv3_2 needs backward computation.
I0222 17:08:08.688776 31885 net.cpp:226] relu3_1 needs backward computation.
I0222 17:08:08.688778 31885 net.cpp:226] conv3_1 needs backward computation.
I0222 17:08:08.688781 31885 net.cpp:228] pool2 does not need backward computation.
I0222 17:08:08.688783 31885 net.cpp:228] relu2_2 does not need backward computation.
I0222 17:08:08.688786 31885 net.cpp:228] conv2_2 does not need backward computation.
I0222 17:08:08.688788 31885 net.cpp:228] relu2_1 does not need backward computation.
I0222 17:08:08.688791 31885 net.cpp:228] conv2_1 does not need backward computation.
I0222 17:08:08.688794 31885 net.cpp:228] pool1 does not need backward computation.
I0222 17:08:08.688796 31885 net.cpp:228] relu1_2 does not need backward computation.
I0222 17:08:08.688799 31885 net.cpp:228] conv1_2 does not need backward computation.
I0222 17:08:08.688802 31885 net.cpp:228] relu1_1 does not need backward computation.
I0222 17:08:08.688804 31885 net.cpp:228] conv1_1 does not need backward computation.
I0222 17:08:08.688807 31885 net.cpp:228] multi_rois does not need backward computation.
I0222 17:08:08.688812 31885 net.cpp:228] rois_data_1_split does not need backward computation.
I0222 17:08:08.688815 31885 net.cpp:228] data does not need backward computation.
I0222 17:08:08.688817 31885 net.cpp:270] This network produces output loss_bbox
I0222 17:08:08.688819 31885 net.cpp:270] This network produces output loss_cls
I0222 17:08:08.688822 31885 net.cpp:270] This network produces output loss_ort
I0222 17:08:08.688848 31885 net.cpp:283] Network initialization done.
I0222 17:08:08.689064 31885 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0222 17:08:09.015305 31885 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/VGG16.v2.caffemodel
I0222 17:08:09.015316 31885 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0222 17:08:09.015318 31885 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0222 17:08:09.025235 31885 net.cpp:761] Ignoring source layer pool5
I0222 17:08:09.104811 31885 net.cpp:761] Ignoring source layer fc8
I0222 17:08:09.104832 31885 net.cpp:761] Ignoring source layer prob
Solving...
F0222 17:08:09.384505 31885 math_functions.cu:79] Check failed: error == cudaSuccess (77 vs. 0)  an illegal memory access was encountered
*** Check failure stack trace: ***
./kitti/scripts/kitti_car_vgg16.sh: line 16: 31885 Aborted                 (core dumped) ./tools/train_net.py --gpu $1 --solver kitti/models/kitti_car/VGG16/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb kitti_car_train --cfg kitti/cfgs/kitti_car_$2.yml
